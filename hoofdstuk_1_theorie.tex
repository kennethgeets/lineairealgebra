\documentclass[lineaire_algebra_oplossingen.tex]{subfiles}
\begin{document}

\chapter{Theorie Hoofdstuk 1}
\section{Bewijzen uit de cursus}

\subsection{Definitie 1.5 p 20}
\label{1.5}
\begin{itemize}
\item Trapvorm
\[
\begin{pmatrix}
\bullet & \cdots & \bullet & \cdots & \bullet & \cdots & \bullet & \cdots & \bullet\\
0 & \cdots & \bullet & \cdots & \bullet & \cdots & \bullet & \cdots & \bullet\\
0 & \cdots & 0 & \cdots & \bullet & \cdots & \bullet & \cdots & \bullet\\
0 & \cdots & 0 & \cdots & \bullet & \cdots & \bullet & \cdots & \bullet\\
0 & \cdots & 0 & \cdots & 0 & \cdots & \bullet & \cdots & \bullet\\
0 & \cdots & 0 & \cdots & 0 & \cdots & 0 & \cdots & \bullet\\
\vdots & \ddots & \vdots & \ddots & \vdots & \ddots & \vdots & \cdots & \bullet\\
0 & \cdots & 0 & \cdots & 0 & \cdots & 0 & \cdots & \bullet\\
\end{pmatrix}
\]

\item Echelonvorm
\[
\begin{pmatrix}
1 & \cdots & \bullet & \cdots & \bullet & \cdots & \bullet & \cdots & \bullet\\
0 & \cdots & 1 & \cdots & \bullet & \cdots & \bullet & \cdots & \bullet\\
0 & \cdots & 0 & \cdots & \bullet & \cdots & \bullet & \cdots & \bullet\\
0 & \cdots & 0 & \cdots & 1 & \cdots & \bullet & \cdots & \bullet\\
0 & \cdots & 0 & \cdots & 0 & \cdots & 1 & \cdots & \bullet\\
0 & \cdots & 0 & \cdots & 0 & \cdots & 0 & \cdots & \bullet\\
\vdots & \ddots & \vdots & \ddots & \vdots & \ddots & \vdots & \cdots & \bullet\\
0 & \cdots & 0 & \cdots & 0 & \cdots & 0 & \cdots & \bullet\\
\end{pmatrix}
\]

\item Rijgereduceerd
\[
\begin{pmatrix}
1 & \cdots & 0 & \cdots & 0 & \cdots & 0 & \cdots & \bullet\\
0 & \cdots & 1 & \cdots & 0 & \cdots & 0 & \cdots & \bullet\\
0 & \cdots & 0 & \cdots & 0 & \cdots & 0 & \cdots & \bullet\\
0 & \cdots & 0 & \cdots & 1 & \cdots & 0 & \cdots & \bullet\\
0 & \cdots & 0 & \cdots & 0 & \cdots & 1 & \cdots & \bullet\\
0 & \cdots & 0 & \cdots & 0 & \cdots & 0 & \cdots & \bullet\\
\vdots & \ddots & \vdots & \ddots & \vdots & \ddots & \vdots & \cdots & \bullet\\
0 & \cdots & 0 & \cdots & 0 & \cdots & 0 & \cdots & \bullet\\
\end{pmatrix}
\]
\end{itemize}


\subsection{Propositie 1.8 p 21}
\label{1.8}

\subsubsection*{Te Bewijzen}
Elke matrix is rij-equivalent met een matrix in echelonvorm en met een matrix die rij-gereduceerd is.

\subsubsection*{Bewijs}
\begin{proof}
Zie p 20 voor een herhaling van wat echelonvorm en rij-gereduceerd precies betekent.\\
Zij $A$ een willekeurige $m\times n$ matrix. Kies een rij van deze matrix waarvoor het leidende element het meest naar links staat van alle rijen uit $A$. Dit is rij $i$. We voeren nu de operatie $R_1 \leftrightarrow R_i$ uit. De rij met waarvan het leidend element het meest naar links staat is nu de eerste rij. Vervolgens voeren we een andere elementaire rijoperatie uit op rij $1$, namelijk $R_1\longmapsto \lambda R_1$ waarbij 
\[
\lambda = \frac{1}{\text{leidende element van } R_1}
\]
De matrix ziet er dan als volgt uit. Er staan al dan niet een aantal nulkolommen op de eerste plaatsen. Er staat een $1$ op de eerste rij op de eerste niet-nul kolom.
De elementen onder de besproken $1$ zullen we $0$ maken door deze elementaire rij-operatie uit te voeren waarbij $\lambda_j$ het element in de kolom van de besproken $1$ is op rij $j$.
\[
R_j \longmapsto R_j - \lambda_jR_1
\]
Nu we onder de besproken $1$ allemaal nullen hebben, kunnen we de beschreven procedure toepassen op de deelmatrix rechts onder de $1$. De procedure stopt wanneer er enkel nog nullen overblijven of als de matrix op geraakt.\\\\
Vervolgens kunnen we van rechtsonder naar linksboven werken zoals hierboven beschreven.
\end{proof}


\subsection{Stelling 1.11 p 23}
\label{1.11}
Zij $A$ een matrix van de volgende vorm die overeen komt met een stelsel.
\[
A =
\left(
\begin{array}{c c c c c c c c c c  c | c}
1 & \bullet & \bullet & \bullet & \cdots & & & & & & \bullet & c_1\\
0 & 1 & \bullet & \bullet & \cdots & & & & & & \bullet & c_2\\
0 & 0 & 1 & \bullet & \cdots & & & & & & \bullet & c_3\\
0 & 0 & 0 & 0 & 1 & \bullet & \cdots & & & & \bullet & \vdots\\
0 & 0 & 0 & 0 & 0 & 0 & \cdots & 1 & \bullet & \cdots  & \bullet & c_r\\
0 & 0 & 0 & 0 & 0 & 0 & \cdots & 0 & 0 & \cdots & \bullet & c_{r+1}\\
0 & \cdots & \cdots & \cdots & \cdots & \cdots & \cdots & \cdots & \cdots & \cdots & 0 & c_{r+2}\\
\vdots & \ddots& \ddots& \ddots& \ddots& \ddots& \ddots& \ddots& \ddots & \ddots & \vdots & \vdots\\
0 & \cdots & \cdots & \cdots & \cdots & \cdots & \cdots & \cdots & \cdots & \cdots & 0 & c_{m}\\
\end{array}
\right)
\]

\subsubsection*{Te bewijzen}
\begin{enumerate}
\item Dit stelsel heeft geen oplossingen $\Leftrightarrow \exists i: c_i \neq 0$.
\item Dit stelsel heeft precies \'e\'en oplossing $\Leftrightarrow (\forall i \in \{r+1,...,m\}: c_i=0) \wedge r=n$. 
\item oneindig veel oplossingen $\Leftrightarrow (\forall i \in \{r+1,...,m\}: c_i=0) \wedge r\neq n$.
\end{enumerate}

\subsubsection*{Bewijs}
\begin{proof}
\begin{enumerate}
\item Stel dat er een $i$ bestaat zodat $c_i \neq 0$, dan komt rij $i$ van de matrix overeen met de volgende vergelijking.
\[
0 = c_i \text{ met } c_i \neq 0
\]
Dit is uiteraard onwaar en bijgevolg heeft het stelsel dus geen oplossingen.
\item
Dit geval houdt in dat rij $r$ overeen komt met een vergelijking met $1$ onbekende en $1$ variabele
Deze vergelijking heeft precies \'e\'en oplossing.
Wanneer we in het stelsel nu de oplossing van die ene vergelijking invullen vinden we telkens op de vorige rij een vergelijking met $1$ onbekende die oplosbaar is.
Zo kunnen we recursief doorgaan om de oplossing te vinden.
\item
Als $r < n$, dan bestaat er een $i$ zodat rij $i$ overeen komt met een vergelijking $0=0$.
Deze vergelijking is niet slechts triviaal waar, maar dit betekent ook dat de $i$-de variabele vrij te kiezen is in de oplossing.
Het stelsel heeft dus oneindig veel oplossingen.
\end{enumerate}


\subsection{Eigenschap 1.16 p 28}
\label{1.16}
Zij $A,B \in \mathbb{R}^{m\times n} $ en $\lambda \in \mathbb{R}$
Noem het element op de $i$de rij, op de $j$de kolom van matrix $X$ $X_{ij}$.

\subsubsection*{Te bewijzen}
\begin{enumerate}
\item $(A^T)^T = A$
\item $(A+B)^T = A^T + B^T$
\item $(\lambda A)^T=\lambda A^T$
\end{enumerate}

\subsubsection*{Bewijs}
\begin{enumerate}
\item Voor elke matrix $A$ het volgende. $\forall i\in \{1,...,m\} ,j \in \{1,...,n\}:$
\[
A^T_{ij} = A_{ji}
\]
\[
(A^T)^T = A_{ij}
\]
\item Voor elke matrix $A$ en $B$ geldt het volgende. $\forall i\in \{1,...,m\} ,j \in \{1,...,n\}:$
\[
((A+B)^T)_{ij} = A_{ji}+B_{ji}= (A^T)_{ij} + (B^T)_{ij}
\]
\item Voor elke matrix $A$ geldt het volgende. $\forall i\in \{1,...,m\} ,j \in \{1,...,n\}:$
\[
((\lambda A)^T)_{ij} = (\lambda A)_{ji} = \lambda A_{ji}
\]
\end{enumerate}
\end{proof}


\subsection{Eigenschap 1.19 p 29}
\label{1.19}
Zij $A,B,C \in R^{m\times n}$ en $\lambda, \mu \in \mathbb{R}$.

\subsubsection*{Te Bewijzen}
\begin{enumerate}
\item \[ (A+B)+C=A+(B+C) \]
\item \[ A+O = A = O+A \]
\item \[ A + (-A) = O \]
\item \[ A+B = B+A \]
\item \[ \lambda(A+B) = \lambda A+ \lambda B \]
\item \[ (\lambda+\mu)A = \lambda A+\mu A \]
\item \[ \lambda(\mu A) = (\lambda\mu)A\]
\item \[ 1A =A \]
\end{enumerate}

\subsubsection*{Bewijzen}
\begin{proof}
\begin{enumerate}
\item 
\[
((A+B)+C)_{ij} = (A_{ij} + B_{ij}) + C_{ij} = A_{ij} + (B_{ij} + C_{ij}) = (A+(B+C))_{ij}
\]
\item
\[ (A+O)_{ij} = A_{ij} + 0 = A_{ij} = 0 + A_{ij} = (O+A)_{ij} \]
\item
\[ (A + (-A))_{ij} = A_{ij} + (-A)_{ij} = 0 = O_{ij} \]
\item
\[ (A+B)_{ij} = A_{ij} + B_{ij} = B_{ij} + A_{ij} = (B+A)_{ij} \]
\item
\[ (\lambda(A+B))_{ij} = \lambda(A+B)_{ij} = \lambda (A_{ij} + B_{ij}) = \lambda A_{ij}+ \lambda B_{ij}  = \lambda A+ \lambda B \]
\item
\[ ((\lambda+\mu)A)_{ij} = (\lambda+\mu)A_{ij} = \lambda A_{ij}+\mu A_{ij} = \lambda A+\mu A \]
\item
\[ (\lambda(\mu A))_{ij} = \lambda(\mu A)_{ij} =\lambda\mu A_{ij} = (\lambda\mu)A_{ij}\]
\item
\[ (1A)_{ij}= 1A_{ij} =A_{ij} \]
\end{enumerate}
\end{proof}


\subsection{Eigenschap 1.22 p 31}
\label{1.22}
Zij $A,B,C$ matrices met passende afmetingen en $\lambda \in \mathbb{R}$.

\subsubsection*{Te Bewijzen}
\begin{enumerate}[(a)]
\item \[ A\cdot (B+C) = A\cdot B + A \cdot C\]
\item \[ (A+B) \cdot C = A\cdot C + B \cdot C \]
\item \[ (A\cdot B)^T  = B^T \cdot A^T \]
\item \[ \lambda(A\cdot B) = (\lambda A)\cdot B = A \cdot (\lambda B)\]
\item \[ A \cdot \mathbb{I}_{n} = A \]
\item \[ \mathbb{I}_{n} \cdot B = B \]
\item \[ A\cdot (B\cdot C) = (A\cdot B) \cdot C\]
\end{enumerate}

\subsubsection*{Bewijs}
\begin{proof}
We bewijzen elk deel door de eigenschap te bewijzen voor een willekeurig element van de beschreven uitdrukking.
\begin{enumerate}[(a)]
\item 
\[ (A\cdot (B+C))_{ij} = \sum_{i=1}^nA_{ij}(B+C)_{jk}\]
\[ = \sum_{i=1}^n(A)_{jk}(B_{ij}+C_{jk}) = \sum_{i=1}^n (A_{ij}B_{jk}+A_{ij}C_{jk}) = \sum_{i=1}^nA_{ij}B_{jk} + \sum_{i=1}^nA_{ij}C_{jk} = \]
\[ (A\cdot B)_{ij} + (A \cdot C)_{ij} = (A\cdot B + A \cdot C)_{ij}\]

\item 
\[ ((A+B) \cdot C)_{ij} = \sum_{j=1}^n(A+B)_{ij}C_{jk}\]
\[ = \sum_{j=1}^n(A_{ij}+B_{ij})C_{jk} = \sum_{j=1}^n (A_{ij}C_{jk}+B_{ij}C_{jk}) = \sum_{j=1}^nA_{ij}C_{jk} + \sum_{j=1}^nB_{ij}C_{jk} = \]
\[ (A\cdot C)_{ij} + (B \cdot C)_{ij} = (A\cdot C + B \cdot C)_{ij} \]

\item 
\[ ((A\cdot B)^T)_{ij}  = (A\cdot B)_{ji}\]
\[ = \sum_{j=1}^nA_{kj}B_{ji} = \sum_{j=1}^nB_{ji}A_{kj} = \sum_{j=1}^nB^T_{ij}A^T_{jk} = (B^T \cdot A^T)_{ij} \]

\item 
\[ (\lambda(A\cdot B))_{ij} = \lambda(A\cdot B)_{ij} = \lambda\sum_{i=1}^nA_{ij}B_{jk}\]
\[ = \sum_{i=1}^n(\lambda A_{ij})B_{jk} = ((\lambda A)\cdot B)_{ij} \]
\[ = \sum_{i=1}^nA_{ij}(\lambda B_{jk}) = (A \cdot (\lambda B))_{ij}\]

\item 
\[ (A \cdot \mathbb{I}_{n})_{ij} = \sum_{i=1}^nA_{ij}\mathbb{I}_{jk} = (A)_{ij} \]

\item 
\[ (\mathbb{I}_{n} \cdot B)_{ij} =  \sum_{i=1}^n\mathbb{I}_{ij}B_{jk} =  (B)_{ij} \]

\item
\[
(A\cdot (B\cdot C))_{ij}
= \sum_{j=1}^n A_{ij}\cdot (B\cdot C)_{jk}
= \sum_{j=1}^n A_{ij}\cdot \left( \sum_{l=1}^o B_{jl}\cdot C_{lk} \right)
= \sum_{j=1}^n \sum_{l=1}^o A_{ij}\cdot B_{jl}\cdot C_{lk}
\]
\[
= \sum_{l=1}^o \sum_{j=1}^n  A_{ij}\cdot B_{jl}\cdot C_{lk}
= \sum_{l=1}^o \left(\sum_{j=1}^n  A_{ij}\cdot B_{jl}\right)\cdot C_{lk}
= \sum_{l=1}^o (A\cdot B)_{il} \cdot C_{lk}
= ((A\cdot B) \cdot C)_{ij}
\]

\end{enumerate}
\end{proof}


\subsection{Stelling 1.26 p 33}
\label{1.26}
Zij $AX=B$ een stelsel van eerstegraads vergelijkingen in matrixvorm.

\subsubsection*{Te Bewijzen}
Een stelsel van eerstegraadsvergelijkingen heeft ofwel geen oplossingen, ofwel juist \'e\'en oplossing, ofwel oneindig veel oplossingen.

\subsubsection*{Bewijs}
\begin{proof}
Bewijs uit het ongerijmde.\\
Als het stelsel niet oplosbaar is, zijn er geen oplossingen. Als het stelsel oplosbaar is, is er minstens \'e\'en oplossing. We tonen aan dat zodra er twee oplossingen zijn, er ook oneindig veel zijn.\\
Stel dat er twee oplossingen zijn van het stelsel, $X_1$ en $X_2$. Het is nu makkelijk te zien dat $X^(\lambda) = X_1 + \lambda(X_2-X_1)$ ook een oplossing is van het stelsel. Omdat we $\lambda$ vrij kunnen kiezen zijn dus er oneindig veel oplossingen van het stelsel.
\end{proof}


\subsection{Eigenschap 1.29 p 34}
\label{1.29}
\subsubsection*{Te Bewijzen}
Als $A$ de linker inverse is van $B$ dan is $B^T$ de linker inverse van $A$.

\subsubsection*{Bewijs}
\begin{proof}
\[\mathbb{I} = AB= (AB)^T = B^TA^T = \mathbb{I}\]
\end{proof}


\subsection{Stelling 1.30 p 34}
\subsubsection*{Te Bewijzen}
Als een vierkante matrix $A$ een links inverse $B$ en een rechtse $C$ heeft dan geldt $B=C$.

\subsubsection*{Bewijs}
\begin{proof}
$B$ en $C$ moeten dezelfde afmetingen hebben als $A$, anders zijn de vermenigvuldigingen niet gedefinieerd.
\[B = B\mathbb{I}\]
\[B = B (AC)\]
\[B = (BA)C\]
\[B = \mathbb{I}C\]
\[B = C\]
\end{proof}


\subsection{Stelling 1.32 p 35}
\label{1.32}
$A$ en $B$ zijn inverteerbare matrices van passende afmetingen.
\subsubsection*{Te Bewijzen}
$AB$ is ook inverteerbaar en het volgende geldt.
\[
(AB)^{-1} = B^{-1}A^{-1}
\]

\subsubsection*{Bewijs}
\begin{proof}
$$\mathbb{I} = \mathbb{I}$$
$$\mathbb{I} = A\cdot A^{-1}$$
$$\mathbb{I} = A\cdot \mathbb{I} \cdot A^{-1}$$
$$\mathbb{I} = A\cdot (B\cdot B^{-1}) \cdot A^{-1}$$
$$\mathbb{I} = A\cdot B\cdot (B^{-1} \cdot A^{-1})$$
We zien dus dat $(B^{-1} \cdot A^{-1})$ de rechts inverse is van van $A \cdot B$. 
$$\mathbb{I} = \mathbb{I}$$
$$\mathbb{I} = B^{-1}\cdot B$$
$$\mathbb{I} = B^{-1}\cdot \mathbb{I}\cdot B$$
$$\mathbb{I} = B^{-1}\cdot (A^{-1}\cdot A) \cdot B$$
$$\mathbb{I} = (B^{-1} \cdot  A^{-1})\cdot (A\cdot B)$$
Bovenstaande gelijkheid toont aan dat $(B^{-1} \cdot A^{-1})$ bovendien de links inverse is van $A \cdot B$. 
Dit houdt in dat $(B^{-1} \cdot A^{-1}) = (AB)^{-1}$ geldt.
\end{proof}


\subsection{Stelling 1.35 p 37}
\label{1.35}
\subsubsection*{Te Bewijzen}
Elementaire matrices zijn inverteerbaar.

\subsubsection*{Bewijs}
\begin{proof}
We zullen dit bewijzen door voor elke elementaire matrix de inverse te construeren.
\begin{itemize}
\item $E_1: R_i\mapsto \lambda R_i$
\[
E_1^{-1}=
\begin{pmatrix}
1 & 0 & 0 & \cdots & 0 & 0\\
0 & 1 & 0 & \cdots & 0 & 0\\
\vdots & \vdots & \ddots & \vdots& & \vdots\\
0 & 0 & \cdots & \frac{1}{\lambda} & \cdots & 0\\
\vdots & \vdots & & \vdots& \ddots & \vdots\\
0 & 0 & \cdots & 0 & \cdots &1
\end{pmatrix}
\]

\item $E_2: R_i \leftrightarrow R_j$
\[
E_2^{-1}=
\begin{pmatrix}
1 & 0 & \cdots & 0 & \cdots & 0 & \cdots & 0\\
0 & 1 & \cdots & 0 & \cdots & 0 & \cdots & 0\\
\vdots & \vdots & \ddots & \vdots& & \vdots & &\vdots\\
0 & 0 & \cdots & 0 & \cdots & 1 & \cdots & 0\\
\vdots & \vdots & & \vdots& \ddots & \vdots & &\vdots\\
0 & 0 & \cdots & 1 & \cdots & 0 & \cdots & 0\\
\vdots & \vdots & & \vdots & & \vdots & \ddots & \vdots\\
0 & 0 & \cdots & 0 & \cdots & 0 & \cdots & 0
\end{pmatrix}
\]
\item $R_3: R_i \mapsto R_i \lambda R_j$
\[
E_3^{-1}=
\begin{pmatrix}
1 & 0 & \cdots & 0 & \cdots & 0 & \cdots & 0\\
0 & 1 & \cdots & 0 & \cdots & 0 & \cdots & 0\\
\vdots & \vdots & \ddots & \vdots& & \vdots & &\vdots\\
0 & 0 & \cdots & 1 & \cdots & -\lambda & \cdots & 0\\
\vdots & \vdots & & \vdots& \ddots & \vdots & &\vdots\\
0 & 0 & \cdots & 0 & \cdots & 1 & \cdots & 0\\
\vdots & \vdots & & \vdots & & \vdots & \ddots & \vdots\\
0 & 0 & \cdots & 0 & \cdots & 0 & \cdots & 0
\end{pmatrix}
\]
\end{itemize}
\end{proof}


\subsection{Stelling 1.36 p 38}
\label{1.36}
Zij $A$ een $n\times n$ matrix.

\subsubsection*{Te Bewijzen}
De volgende beweringen zijn equivalent.
\begin{enumerate}
\item De matrix $A$ heeft een links inverse
\item Het stelsel $AX = 0$ heet enkel de evidente oplossing $X=0$
\item De matrix $A$ is rij-equivalent met de eenheidsmatrix $\mathbb{I}_n$.
\item De matrix $A$ is een product van elementaire matrices.
\item De matrix $A$ is inverteerbaar.
\item De matrix $A$ heeft een rechts inverse
\end{enumerate}

\subsubsection*{Bewijs}
\begin{proof}
\textbf{$1 \rightarrow 2$ }\\
Stel dat $B$ de linker inverse is van $A$.
\[
AX = 0 
\]
\[
\Rightarrow X = (B\cdot A)\cdot X = B \cdot (A\cdot X) = B\cdot 0=0
\]
De enige oplossing is dus de nuloplossing.\\\\
\textbf{$2 \rightarrow 3$ }\\
$A\cdot X = 0$ heeft enkel de nuloplossing. Alle variabelen van het stelsel zijn gebonden variabelen. De matrix is dus rij-equivalent met de eenheidsmatrix.\\\\
\textbf{$3 \rightarrow 4$ }\\
We bewijzen dat elementaire matrices bestaan zodat $A$ gelijk is aan het product van die elementaire matrices.
\[
E_{k}\cdot E_{k-1}\cdot ... \cdot E_{2}\cdot E_{1}\cdot A = \mathbb{I}_{n}
\]
Elke elementaire matrix is inverteerbaar en de inverse is telkens weer een elementaire matrix.\\
We vermenigvuldigen stap voor beide kanten met de inverse die het meeste links staan:
$$(E_{k})^{-1} \cdot E_{k}\cdot E_{k-1}\cdot ... \cdot E_{2}\cdot E_{1}\cdot A = (E_{k})^{-1} \cdot \mathbb{I}_{n}$$
$$\mathbb{I}_n\cdot E_{k-1}\cdot ... \cdot E_{2}\cdot E_{1}\cdot A = (E_{k})^{-1} $$
$$...$$
Dit blijven we zo herhalen tot we het volgende krijgen:
\[
A = E_{1}^{-1}\cdot E_{2}^{-1}\cdot ...\cdot  E_{k}^{-1}
\]
$A$ is dus een product van elementaire matrices.
\\\\
\textbf{$4 \rightarrow 5$ }\\
We weten dat $A$ een product is van elementaire matrices.
\[
A = E_1\cdot E_2 \cdot ... \cdot E_k
\]
De elementaire matrices zijn inverteerbaar. De inverse van $A$ bestaat en valt als volgt te construeren.
\[
A^{-1} = (E_1\cdot E_2 \cdot ... \cdot E_k)^{-1} = (E_k^{-1}\cdot ...\cdot E_2^{-1}\cdot E_1^{-1})
\]
\textbf{$5 \rightarrow 6$ }\\
Als $A$ inverteerbaar is, dan is de inverse van $A$ ook de rechter inverse van $A$.\\\\
\textbf{$6 \rightarrow 1$ }\\
Stel $B$ is de rechter inverse van $A$.
\[
A\cdot B = \mathbb{I}_n
\]
$A$ is dan de linker inverse van $B$. dus alle bovenstaande eigenschappen gelden voor $B$. $B$ is inverteerbaar dus $A = B^{-1}$.
\[
B\cdot A\cdot B = B
\]
\[
B\cdot A \cdot B \cdot B^{-1} = B \cdot B^{-1}
\]
\[
B\cdot A = \mathbb{I}_n
\]
$B$ is dus ook de linker inverse van $A$.
\end{proof}


\subsection{Lemma 1.41 p 40}
\label{1.41}
Zij $A,B \in \mathbb{R}^{n\times n}$.

\subsubsection*{Te Bewijzen}
\begin{enumerate}
\item $A,B$ benedendriehoeks $\Rightarrow A\cdot B$ benedendriehoeks.
\item $A,B$ bovendriehoeks $\Rightarrow A\cdot B$ bovendriehoeks.
\end{enumerate}

\subsubsection*{Bewijs}
\begin{proof}
\[
(A\cdot B)_{ij} = \sum_{b=1}^nA_{ik}B_{kj} 
\]
\begin{enumerate}
\item We weten dat de  $\sum_{b=1}^nA_{ik}B_{kj} = 0$ als $i>j$ want $A_{ik} = 0$ als $i>k$ en $B_{kj}=0$ als $k>j$.
\item We weten dat de  $\sum_{b=1}^nA_{ik}B_{kj} = 0$ als $j>i$ want $A_{ik} = 0$ als $k>i$ en $B_{kj}=0$ als $j>k$.
\end{enumerate}
\end{proof}


\subsection{Stelling 1.42 p 41}
\label{1.42}
Zij $A$ een $m\times n$ matrix die in echelonvorm gebracht kan worden door elementaire rijoperaties zonder rij omwisselingen te gebruiken.

\subsubsection*{Te Bewijzen}
Er bestaat een $m\times m$ benedendriehoeksmatrix $L$ en een $m\times n$ bovendriehoeksmatrix $U$ zodat $A = L\cdot U$.

\subsubsection*{Bewijs}
Om de matrix $A$ in echelonvorm te brengen moeten we deze links vermenigvuldigen met elementaire matrices die benedendriehoeksmatrices zijn als er geen rij omwisselingen nodig zijn. Noem deze elementaire matrices $E_1,...,E_k$.
\[
E_k\cdot ... \cdot E_1 \cdot A = U
\]
De resulterende matrix $U$ is in echelonvorm, dus een bovendriehoeksmatrix. We weten dat elementaire matrices inverteerbaar zijn\footnote{Zie Stelling 1.35 p 37} dus de volgende stelling geldt.
\[
A = E_1^{-1}\cdot ...\cdot E_k^{-1} \cdot U = L\cdot U
\]
We weten ook dat de inverse van de originele elementaire matrices benedendriehoeks matrices zijn, dus $L = E_1^{-1}\cdot ...\cdot E_k^{-1}$ is ook benedendriehoeks\footnote{Zie Lemma 1.41 p 40}.
$L\cdot U$ heet de $LU$-decompositie.


\subsection{Stelling 1.45 p 43}
\label{1.45}
Zij $A$ een inverteerbare $n\times n$ matrix die via rijoperaties tot in trapvorm kan gebracht worden zonder rijen te verwisselen.

\subsubsection*{Te Bewijzen}
Er bestaat een unieke benedendriehoeksmatrix $L$ met enkel $1$ op de diagonaal en een unieke bovendriehoeksmatrix $U$ zodat $A=LU$.

\subsubsection*{Bewijs}
\begin{proof}
Bewijs uit het ongerijmde.\\
Stel dat $L$ en $U$ niet uniek zijn. Dan bestaan er $L_1 \neq L_2,U_1 \neq U_2$ zodat de volgende formule geldt.
\[
A = L_1U_1=L_2U_2
\]
$L_1$ en $L_2$ zijn hier benedendriehoeksmatrices met enkel $1$ op de diagonaal. $U_1$ en $U_2$ zijn hier bovendriehoeksmatrices.
\[
L_2^{-1}L_1 = U_2U_1^{-1}
\]
De matrix in het linkerlid is een benedendriehoeksmatrix met enkel $1$ op de diagonaal en de matrix in het rechterlid is een bovendriehoeksmatrix\footnote{Zie Lemma 1.41 p 40}.
Een bovendriehoeksmatrix kan enkel gelijk zijn aan een benedendriehoeksmatrix met enkel $1$ op de hoofddiagonaal als ze beide gelijk zijn aan de eenheidsmatrix.
\end{proof}


\end{document}
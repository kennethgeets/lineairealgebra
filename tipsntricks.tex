\documentclass[lineaire_algebra_oplossingen.tex]{subfiles}
\begin{document}

\chapter{Tips}
\section{Bewijzen In het algemeen}
Omdat informatici doorgaans geen bewijzen en redeneren hebben gevolgd is hier een overzicht van de meest voorkomende bewijstechnieken.

\subsection{Algemene Tips}
\subsubsection{Zinnen}
Elke bewijs is voor de mensen die het lezen en uzelf. Alles in wiskunde is per definitie al waar. Bewijzen dienen dus enkel om uzelf en anderen te \emph{overtuigen} dat het waar is. Een bewijs moet daarom duidelijk leesbaar en begrijpbaar zijn. Afhankelijk van voor wie we iets bewijzen, gaan we meer of minder in detail. 

De proffen hebben graag een gedetailleerd bewijs, omdat ze na moeten gaan of \emph{jij} het kent. Ze moeten niet nagaan of de stelling waar is. Houd dit in gedachten wanneer u bewijzen schrijft.

Tenslotte is het een goed idee om een goede kennis te ontwikkelen van de Nederlandse connectieven zoals 'hieruit volgt', 'daarom', 'dus', 'want', enz.... Deze maken bewijzen namelijk gemakkelijk duidelijker.
\subsubsection{Gegevens}
Een bewijs heeft meestal de vorm beschreven in figuur \ref{algemeen_bewijs}. Merk op dat dit zeer sterk lijkt op het sjabloon van een oefening in de fysica, maar dan zonder het 'gegevens' deel. Dit wordt meestal weggelaten in bewijzen omdat in de wiskunde absoluut waar is. Als er iets gebruikt wordt moet er echter wel verwezen worden naar een uitleg waarom het waar is.
\begin{figure}[H]
\begin{itemize}
\item Naamgeving
\item Te Bewijzen
\item Bewijs
\end{itemize}
\caption{Algemene structuur van een bewijs}
\label{algemeen_bewijs}
\end{figure}
In het naamgeving deel benoemen we de wiskundige elementen die van toepassing zijn, zodat we erover kunnen praten en zodat we niet alle eigenschappen ervan meer moeten herhalen.\\
Bvb: Zij $L$ een surjectieve afbeelding. (We moeten nu de eigenschappen van surjectiviteit niet meer herhalen zolang we ernaar verwijzen als we ze gebruiken.)

\subsection{Direct Bewijs}
Als een stelling van de vorm $P \Rightarrow Q$ is, kunnen we deze soms met een direct bewijs bewijzen. We voegen de hypothese $P$ toe aan de gegevens en proberen daaruit $Q$ te concluderen. 

\subsubsection{Gevalsonderscheid}
Soms is het moeilijk om een direct bewijs op te stellen zonder een gevalonderscheid te maken. We kunnen het bewijs dan als het ware opsplitsen voor elk geval. Doorgaans doen we dit zo weinig mogelijk omdat het voor onnodig extra werk kan zorgen.

\subsubsection{Achterwaarts Bewijzen}
Soms is de hypothese simpeler dan het gevolg, dan kan het makkelijker zijn om het bewijs achterwaarts te construeren. We moeten dan wel goed opletten dat we ofwel equivalenties gebruiken, ofwel omgekeerde implicaties.

\subsection{Bewijs uit het Ongerijmde}
Omdat een bewering ofwel waar is, ofwel niet waar is, maar daar niets tussen zit kunnen we een bewering ook als volgt bewijzen. We gaan ervan uit dat de te bewijzen stelling niet waar is, en proberen een contradictie (een bewering van de vorm $P\wedge\neg P$) te bekomen.

\subsection{Contrapositie}
Een implicatie $P\Rightarrow Q$ is equivalent aan $\neq Q\Rightarrow \neq P$. Als we dus dit tweede kunnen bewijzen is het eerste ook bewezen.

\subsection{Bewijs met volledige inductie}
Een bewering van de vorm $\forall p \in P: Q(p)$ kunnen we soms bewijzen via volledige inductie. Dit gebeurt in twee stappen.
\begin{enumerate}
\item Basis stap\\
We bewijzen dat de bewering $Q(p_i)$ geldt, waarin $p_i$ het kleinste element uit $P$ is.
\item Inductie stap\\
We gaan er nu van uit dat $Q(p_k)$ geldt voor een bepaalde $p$ (inductie hypothese). Vervolgens bewijzen we dat daaruit volgt dat de bewering geldt voor $p_{k+1}$.
\end{enumerate}

\subsection{Overzicht}
Dit is enkel een overzicht van de mogelijkheden. Niet elke optie is altijd mogelijk. Meestal zijn bewijzen niet eenvoudig te categoriseren en zijn ze bijgevolg een samenstelling van meerdere constructies.
\begin{itemize}
\item En: $P\wedge Q$
\begin{itemize}
\item Direct Bewijs - Bewijs dat zowel $P$ als $Q$ altijd gelden.
\item Bewijs uit het ongerijmde - Bewijs via gevalsonderscheid dat er een contradictie optreedt wanneer \'e\'en van de beweringen niet geldt.
\end{itemize}
\item Of: $P\vee Q$
\begin{itemize}
\item Direct Bewijs - Bewijs dat \'e\'en van de bewering altijd waar is.
\item Gevalonderscheid - Bewijs voor elk geval dat \'e\'en van de beweringen geldt.
\item Bewijs uit het ongerijmde - Ga ervan uit dat zowel $P$ als $Q$ niet waar zijn en kom tot een contradictie.
\end{itemize}
\item Implicatie: $P\Rightarrow Q$
\begin{itemize}
\item Direct Bewijs - Ga uit van $P$ en ga via implicaties naar $Q$/
\item Gevalonderscheid in $P$
\item Bewijs uit het ongerijmde - Ga ervan uit dat $P$ geldt maar $Q$ niet en kom tot een contradictie.
\item Contrapositie - Bewijs $\neq Q\Rightarrow \neq P$
\end{itemize}
\item Er bestaat...: $\exists p : Q(p)$
\begin{itemize}
\item Construeer $p$ voor elke mogelijke $Q(p)$.
\end{itemize}
\item Voor alle...: $\forall p: Q(p)$
\begin{itemize}
\item Bewijs uit het ongerijmde - Ga ervan uit dat er een $p$ bestaat waarvoor $Q$ niet geldt en kom tot een contradictie.
\item Bewijs door volledige inductie.
\end{itemize}
\end{itemize}


\chapter{Handige algoritmes}
\section{Een stelsel met parameter(s) oplossen}
\subsection*{Generiek}
Stel dat we de oplossingen van het volgende stelsel moeten vinden voor elke mogelijk $a \in \mathbb{R}$.
\[
\left\{
\begin{array}{c c c c c c c c c}
c_{11}x_1 &+& c_{12}x_2 &+& \cdots &-& c_{1n} &=& 0\\
c_{21}x_1 &+& c_{22}x_2 &+& \cdots &-& c_{2n} &=& 0\\
\vdots && \vdots && \ddots && \vdots && \vdots\\
c_{m1}x_1 &+& c_{m2}x_2 &+& \cdots &-& c_{mn} &=& 0\\
\end{array}
\right.
\]
De idee is om de matrix op te stellen die overeenkomt met dit stelsel en deze te reduceren tot we de oplossingen kunnen aflezen.
(Dit hoeft geen volledige rijreductie te zijn. Een echelonvorm is vaak ook al handig.)
Hierbij zullen we vaak een gevalonderscheid moeten maken voor de parameters.
We proberen echt zo lang mogelijk geen gevalonderscheid te maken.
\[
\begin{pmatrix}
c_{11} &c_{12} & \cdots & c_{1n}\\
c_{21} & c_{22} & \cdots & c_{2n}\\
\vdots & \vdots & \ddots & \vdots \\
c_{m1} & c_{m2} & \cdots & c_{mn}\\
\end{pmatrix}
\rightarrow
\left(
\begin{array}{c c c c | c}
1 & 0 & \cdots & 0 & o_1\\
0 & 1 & \cdots & 0 & o_2\\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & 1 & o_n\\
\end{array}
\right)
\]

\subsection*{Voorbeeld}
Zie pagina $1.12$ voor een goed voorbeeld.
%TODO nog een voorbeeld verzinnen.

\section{Een LU decompositie construeren}
\subsection*{Generiek}
Stel dat $A$ de matrix is die we willen herleiden tot een LU decompositie.\\\\
We rijreduceren $A$ tot een bovendriehoeksmatrix $U$ maar we houden goed bij welke elementaire rijoperaties $E_1,E_2,..,E_k$ we uitvoeren. Nu zetten we de inverse matrices van deze elementaire matrices in volgorde en vermenigvuldigen we ze om $L$ te krijgen.
\[
L = E_1^{-1} \cdot E_2^{-1} \cdot \cdots \cdot  E_k^{-1}
\] 
Nu hebben we $L$ en $U$ gevonden om de LU decompositie op te stellen.
\[
A = L\cdot U
\]
\subsection*{Voorbeeld}
Zie 1.6.3 pagina 43 voor een goed voorbeeld.
%TODO nog een voorbeeld verzinnen

\section{De determinant van een grote matrix berekenen}
\subsection*{Generiek}
Stel dat $A \in \mathbb{n\times n}$ de matrix is waarvan we de determinant willen berekenen en $A$ groter is dan $3\times 3$.
\[
A = 
\begin{pmatrix}
a_{11} & a_{12} & \cdots & a_{1n}\\
a_{21} & a_{22} & \cdots & a_{2n}\\
\vdots & \vdots & \ddots & \vdots\\
a_{n1} & a_{n2} & \cdots & a_{nn}\\
\end{pmatrix}
\]
We zullen $det(A)$ berekenen door \'e\'en van of een combinatie van twee methoden.
\begin{enumerate}
\item De eerste methode is het ontwikkelen van $A$ naar rijen en/of kolommen tot de nog te berekenen matrices klein genoeg zijn. Een goede tip voor het ontwikkelen is om te ontwikkelen naar de rij/kolom die het meeste nullen bevat.

\item Som kunnen we $A$ rij reduceren naar een makkelijker te ontwikkelen matrix.
In deze methode moeten we goed opletten dat we de juiste co\"effici\"enten niet voor de determinant vergeten te zetten indien nodig.\\\\
\end{enumerate}
De ideale werkwijze is een combinatie van de twee methoden.
Idealiter reduceren we de matrix tot een driehoeksmatrix zodat de determinant het product van de elementen op de hoofddiagonaal is.

\subsection*{Voorbeeld}
We zoeken de volgende determinant.
\[
det(A) =
\begin{vmatrix}
5 & 0 & 0 & 0 & 0\\
1 & 4 & 3 & 2 & 0\\
2 & 0 & 1 & 2 & 3\\
0 & 0 & 4 & 5 & 6\\
0 & 0 & 7 & 8 & 9
\end{vmatrix}
\]
We zullen niet zomaar ontwikkelen maar het net iets intelligenter aanpakken.\\
Op de eerste rij zien we dat er slechts \'e\'en niet nul element staat. Ontwikkelen naar deze rij zal dus makkelijk zijn.
\[
=
5
\cdot
\begin{vmatrix}
4 & 3 & 2 & 0\\
0 & 1 & 2 & 3\\
0 & 4 & 5 & 6\\
0 & 7 & 8 & 9
\end{vmatrix}
\]
Nu zien we in de eerste kolom opnieuw maar \'e\'en element staan dat niet nul is. We ontwikkelen naar deze kolom.
\[
=
5
\cdot
4
\cdot
\begin{vmatrix}
1 & 2 & 3\\
4 & 5 & 6\\
7 & 8 & 9
\end{vmatrix}
\]
De matrix waarvan we determinant nog niet kennen zullen we nu rij reduceren.
\[
=
5
\cdot
4
\cdot
\begin{vmatrix}
1 & 2 & 3\\
0 & -3 & -6\\
0 & -6 & -12
\end{vmatrix}
\]
We zien nu al dat de derde kolom een veelvoud is van de tweede kolom.
De gezochtte determinant is dus $det(A) = 0$.\\\\
Merk op dat deze werkwijze veel sneller is dan domweg ontwikkelen naar willekeurige rijen/kolommen.

\section{Een vrije deelverzameling uitbreiden tot een basis}
Stel dat $D = \{v_1,v_2,...,v_k\}$ de vrije verzameling is die we willen uitbreiden tot een basis van een vectorruimte $(\mathbb{R},V,+)$ van dimensie $n$ ($k\le n$).
\begin{enumerate}
\item Kijk na of $D$ voortbrengend is.
\begin{itemize}
\item $D$ is voortbrengend $\rightarrow$ Stop, $D$ is een  basis voor $V$.
\item $D$ is niet voortbrengend $\rightarrow$ Ga door naar stap $2$.
\end{itemize}
\item Zoek een vector $v_{k+1}$ die lineair onafhankelijk is van de vectoren in $D$ en voeg deze toe aan $D$.
\item Ga terug naar stap $1$.
\end{enumerate}
\section{Een voortbrengende deelverzameling uitdunnen tot een basis}
Stel dat $D = \{v_1,v_2,...,v_k\}$ de voortbrengende verzameling is die we willen uitdunnen tot een basis van een vectorruimte $(\mathbb{R},V,+)$ van dimensie $n$ ($k\ge n$).
\begin{enumerate}
\item Verwijder alle nulvectoren uit $D$.
\item Overloop, in volgorde, alle vectoren uit $D$ en verwijder elke vector die lineair afhankelijk is van de vorige.
\item De resulterende deelverzameling van $D$ is een basis van $V$.
\end{enumerate}

\section{Matrix van basisverandering opstellen}
Zij $\alpha = \{a_1,a_2,...,a_n\}$ en $\beta = \{b_1,b_2,...,b_n\}$ twee basissen van de $n$-dimensionale vectorruimte $(\mathbb{R},V,+)$. Willen we nu de matrix van basisverandering $Id_\alpha^\beta$ opstellen, dan voeren we volgend algoritme uit.
\subsection*{Generiek}
We stellen beide basissen voor volgens dezelfde basis. Vaak is de standaardbasis het makkelijkst. %TODO schrijf een voorbeeld waarvoor dit niet zo is.
De co\"ordinaten van de vectoren $(x_1,x_2,...,x_n)$ en $(y_1,y_2,...,y_n)$ standaardbasissen $\alpha$ en $\beta$ zetten we in de volgende matrix in de kolommen.
\[
\left(
\begin{array}{c c c c | c c c c}
x_{11} & x_{12} & \cdots & x_{1n} & y_{11} & y_{12} & \cdots & y_{1n}\\
x_{21} & x_{22} & \cdots & x_{2n} & y_{21} & y_{22} & \cdots & y_{2n}\\
\vdots & \vdots & \ddots & \vdots & \vdots & \vdots & \ddots & \vdots\\
x_{n1} & x_{n2} & \cdots & x_{nn} & y_{n1} & y_{n2} & \cdots & y_{nn}\\
\end{array}
\right)
\]
We rijreduceren nu deze matrix om aan de rechterkant de gezochte matrix te vinden.
\[
\left(
\begin{array}{c c c c | c c c c}
1 & 0 & \cdots & 0 & z_{11} & z_{12} & \cdots & z_{1n}\\
0 & 1 & \cdots & 0 & z_{21} & z_{22} & \cdots & z_{2n}\\
\vdots & \vdots & \ddots & \vdots & \vdots & \vdots & \ddots & \vdots\\
0 & 0 & \cdots & 1 & z_{n1} & z_{n2} & \cdots & z_{nn}\\
\end{array}
\right)
\]
De gezochte matrix $Id_\alpha^\beta$ is dus de volgende.
\[
Id_\alpha^\beta
=
\begin{pmatrix}
z_{11} & z_{12} & \cdots & z_{1n}\\
z_{21} & z_{22} & \cdots & z_{2n}\\
\vdots & \vdots & \ddots & \vdots\\
z_{n1} & z_{n2} & \cdots & z_{nn}\\
\end{pmatrix}
\]

\subsection*{Voorbeeld}
Zij $\alpha = \{3+2X+X^2,4-X^2,2+X\}$ en $\beta = \{2X^2-1,X+3,-X^2+X\}$.
We schrijven de coordinaten van deze vectoren volgens de standaardbasis in de colommen van de volgende matrix.
\[
\left(
\begin{array}{c c c | c c c}
3 & 4 & 2 & -1 & 3 & 0\\
2 & 0 & 1 & 0 & 1 & 1\\
1 & -1 & 0 & 2 & 0 & 1\\
\end{array}
\right)
\]
Wanneer we dit rijreduceren verkrijgen we rechts de matrix van basisverandering $Id_\alpha^\beta$
\[
Id_\alpha^\beta =
\left(
\begin{array}{c c c | c c c}
1 & 0 & 0 & \frac{7}{3} & \frac{1}{3} & \frac{2}{3}\\
0 & 1 & 0 & \frac{1}{3} & \frac{1}{3} & -\frac{1}{3}\\
0 & 0 & 1 & -\frac{14}{3} & \frac{1}{3} & -\frac{1}{3}\\
\end{array}
\right)
\]

\section{Matrixvoorstelling van lineaire afbeelding ten opzichte van de standaardbasissen}
Zij $L:V\rightarrow W$ een lineaire afbeelding van de $n$-dimensionale vectorruimte $(\mathbb{R},V,+)$ naar de $m$-dimensionale vectorruimte $(\mathbb{R},W,+)$. Willen we nu de matrixvoorstelling van $L$ ten opzichte van de standaard basissen $\epsilon_V$ en $\epsilon_W$.

\subsection*{Generiek}
Als het functievoorschrift van $L$ gegeven is dan zijn de co\"ordinaten van een generische vector $v\in V$ en $w\in W$ makkelijk af te lezen.
De co\"ordinaten van $w$ ten opzichte van de standaardbasis van $V$ zijn een lineaire combinatie van de basisvectoren van $V$. ($w = \lambda_1v_1+\lambda_2v_1+...+\lambda_nv_n$) deze lineaire combinatie zetten we in de rijen van de volgende matrix.
\[
\begin{pmatrix}
\lambda_{11} & \lambda_{12} & \cdots & \lambda_{1n} \\
\lambda_{21} & \lambda_{22} & \cdots & \lambda_{2n} \\
\vdots & \vdots & \ddots & \vdots\\
\lambda_{m1} & \lambda_{m2} & \cdots & \lambda_{mn} \\
\end{pmatrix}
\]
Deze matrix is precies de matrix die we zochten.

\subsection*{Voorbeeld}
Zij $L:R[X]_{\le 4}\rightarrow \mathbb{R}^3: a+bX+cX^2+dX^3+eX^4\mapsto (a+b,c+d+e,-a+3b+c-4e)$.
We zien dat de co\"ordinaten van $(a+b,c+d+e,-a+3b+c-4e)$ ten opzichte van de standaardbasis van $\mathbb{R}^3$ precies in de vector staan en een lineaire combinatie zijn van $a$, $b$, $c$, $d$ en $e$.
Schrijven we deze lineaire combinaties als rijen in de volgende matrix, dan is dit de matrixvoorstelling van $L$ ten opzichte van de standaard basissen.
\[
\begin{pmatrix}
1 & 1 & 0 & 0 & 0\\
0 & 0 & 1 & 1 & 1\\
-1 & 3 & 1 & 0 & -4\\
\end{pmatrix}
\]


\section{Matrix van een lineaire afbeelding ten opzichte van gegeven basissen}
\label{matrix_van_lineaire_afbeeldingen_tov_gegeven_basissen}

\subsection*{Generiek}
\subsubsection*{Opgave}
Zij $L$ een lineaire afbeelding van $V$ naar $W$.
Zij $\alpha$ een basis van $V$ en $\beta$ een basis van $W$.
Zij $\epsilon_1$ de standaarbasis van $V$ en $\epsilon_2$ de standaardbasis van $W$.
Bereken de matrix van $L$ ten opzichte van $\alpha$ en $\beta$.
\subsubsection*{Oplossing}
\begin{enumerate}
\item
Bereken de matrix $L_{\epsilon_1}^{\epsilon_2}$ ten opzichte van de standaardbasissen door de lineaire combinaties af te lezen uit het voorschrift en deze in de rijen van een matrix te zetten.
Dit is een $dimV \times dimW$ matrix.

\item
Bereken de matrices van basisverandering van $\alpha$ naar $\epsilon_1$ en van $\beta$ naar $\epsilon_2$. Bereken ook de inversen ervan indien nodig.

\item
\end{enumerate}


\subsection*{Voorbeeld}
\subsubsection*{Opgave}
Zij $L$ een lineaire afbeelding van $\mathbb{R}^{2\times 2}$ naar $\mathbb{R}[X]_{\le 2}$.
\[
L:
\begin{pmatrix}
a & b\\
c & d\\
\end{pmatrix}
\mapsto
(a+3b) + (5d+2c)X + (3d-8b)X^2
\]
Zij $\alpha$ een basis van $\mathbb{R}^{2\times 2}$ en $\beta$ een basis van $\mathbb{R}[X]_{\le 2}$.
\[
\alpha = 
\left\{ 
\begin{pmatrix}
1 & 2\\
-1 & 2\\
\end{pmatrix}
,
\begin{pmatrix}
-1 & 0\\
0 & 0 
\end{pmatrix}
,
\begin{pmatrix}
1 & 0\\
0 & 2\\
\end{pmatrix}
,
\begin{pmatrix}
0 & -5\\
-4 & 1\\
\end{pmatrix}
\right\}
\]
\[
\beta
=
\left\{
(-2) , (X^2-1), (4X)
\right\}
\]
Zij $\epsilon_1$ de standaarbasis van $\mathbb{R}^{2\times 2}$ en $\epsilon_2$ de standaardbasis van $\mathbb{R}[X]_{\le 2}$.
Bereken de matrix van $L$ ten opzichte van $\alpha$ en $\beta$.

\subsubsection*{Oplossing}
We zullen eerst de matrix van $L$ berekenen ten opzichte van de standaardbasissen, daarna de matrix van basisverandering van $\epsilon_1$ naar $\alpha$ en de matrix van basisverandering van $\epsilon_2$ naar $\beta$. Ten slotte voegen we deze berekeningen samen om de matrix van $L$ te berekenen ten opzichte van $\alpha$ en $\beta$.

\begin{enumerate}
\item Matrixvoorstelling opzichte van de standaardbasissen\\
We lezen de lineaire combinaties van de lineaire afbeelding af in het voorschrift en zetten ze in de rijen van een matrix.
\[
L_{\epsilon_1}^{\epsilon_2} = 
\begin{pmatrix}
1 & 3 & 0 & 0\\
0 & 0 & 2 & 5\\
0 & -8 &0 & 3\\
\end{pmatrix}
\]

\item Matrices van basisverandering\\
We zetten simpelweg de co\"ordinaten van $\alpha$ en $\beta$ ten opzichte van de standaardbasissen $\epsilon_1$ en $\epsilon_2$ in de kolommen van een matrix.
\[
Id_{\alpha}^{\epsilon_1} =
\begin{pmatrix}
1 & -1 & 1 & 0\\
2 & 0 & 0 & -5\\
-1 & 0 & 0 & -4\\
2 & 0 & 2 & 1\\
\end{pmatrix}
\]
\[
Id_{\beta}^{\epsilon_2} =
\begin{pmatrix}
-2 & -1 & 0\\
0 & 0 & 4\\
0 & 1 & 0\\
\end{pmatrix}
\]
Merk op dat $Id_{\epsilon_1}^{\alpha}$ en $Id_{\epsilon_2}^{\beta}$ inverteerbaar zijn, en deze inversen goed van pas zullen komen. Er geldt namelijk het volgende.
\[
Id_{\epsilon_1}^{\alpha}
= (Id_{\alpha}^{\epsilon_1})^{-1}
=
\begin{pmatrix}
0 & \frac{4}{13} & \frac{-5}{13} & 0\\
-1 & \frac{1}{26} & \frac{1}{13} & \frac{1}{2}\\
0 & \frac{-7}{26} & \frac{6}{13} & \frac{1}{2}\\
0 & \frac{-1}{13} & \frac{-2}{13} &0
\end{pmatrix}
\]
\[
Id_{\epsilon_2}^{\beta}
= (Id_{\beta}^{\epsilon_2})^{-1}
= 
\begin{pmatrix}
\frac{-1}{2} & 0 & \frac{-1}{2}\\
0 & 0 & 1\\
0 & \frac{1}{4} & 0
\end{pmatrix}
\]

\item
We voegen nu de berekeningen samen om $L_{\alpha}^{\beta}$ te bekomen. (Let goed op de indices, ze kunnen als hulpmiddel dienen.)
\[
L_{\alpha}^{\beta}
= Id_{\epsilon_2}^{\beta} \cdot L_{\epsilon_1}^{\epsilon_2} \cdot Id_{\alpha}^{\epsilon_1} 
= (Id_{\beta}^{\epsilon_2})^{-1} \cdot L_{\epsilon_1}^{\epsilon_2} \cdot Id_{\alpha}^{\epsilon_1} 
\]
\[
L_{\alpha}^{\beta} = 
\begin{pmatrix}
\frac{-1}{2} & 0 & \frac{-1}{2}\\
0 & 0 & 1\\
0 & \frac{1}{4} & 0
\end{pmatrix}
\cdot
\begin{pmatrix}
1 & 3 & 0 & 0\\
0 & 0 & 2 & 5\\
0 & -8 &0 & 3\\
\end{pmatrix}
\cdot 
\begin{pmatrix}
1 & -1 & 1 & 0\\
2 & 0 & 0 & -5\\
-1 & 0 & 0 & -4\\
2 & 0 & 2 & 1\\
\end{pmatrix}
\]
%TODO uitrekenen


\end{enumerate}




\chapter{Handige definities}
\section{Samenstelling van afbeeldingen}
\label{samenstelling_van_afbeeldingen}
Zij $f: U \rightarrow V$ en $g: V\rightarrow W$ twee afbeeldingen.
\[
\forall x\in U: (f \circ g)(x) = f(g(x))
\]

\section{Injectief}
\label{injectief}
Een afbeelding $L: V \rightarrow W$ is injectief.
\[
L(v) = L(w) \Rightarrow v = w
\]

\section{Surjectief}
\label{surjectief}
Een afbeelding $L: V \rightarrow W$ is surjectief.
\[
\forall w \in W \exists v \in V: w=L(v)
\]

\section{Bijectief}
\label{bijectief}
Een afbeelding $L: V \rightarrow W$ is bijectief als en slechts als deze afbeelding injectief en surjectief is.


\end{document}